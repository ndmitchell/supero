\documentclass{llncs}

\usepackage{url}
\usepackage{bar}

%include polycode.fmt
%include supero.fmt

\newenvironment{fig}
    {\begin{figure}[tbp]\hrule}
    {\end{figure}}

\newcommand{\figend}{\hrule}


\begin{document}

\title{Supero: Making Haskell Faster}

\author{Neil Mitchell and Colin Runciman}

\institute{University of York, UK, \url{http://www.cs.york.ac.uk/~ndm}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
Haskell is a high level functional language, with features like higher order functions and lazy evaluation, which allow succinct representations of programs. These high level features can result in poor runtime speed of generated code, if care is not taken. This paper presents a whole program approach to transformation, which enables substantial speed improvements relative to the GHC, a mature optimising compiler.
\end{abstract}

\section{Introduction}

Haskell can be used to write high level specifications of programs, which can run. Take for example the task of counting the number of words in a file read from the input. In Haskell this program is a single line:

\begin{code}
main = print . length . words =<< getContents
\end{code}

The |getContents| function reads the input as a list of characters, |words| splits this list into a list of words, |length| counts the number of words, and finally |print| writes the value to the screen. The use of |(=<<)| is merely to do sequence the actions, and can be ignored for those unfamiliar with Haskell and monadic IO.

Compared to a C program to perform this task (see Figure \ref{fig:c_words}), the Haskell version is more concise, more specification orientated and easier to convince others of its correctness. Unfortunately with all these good points,  it is also three times slower than the C version.

\begin{fig}
\bigskip
\begin{verbatim}
int main()
{
	int i = 0;
	int c, last_space = 1, this_space;
	while ((c = getchar()) != EOF) {
		this_space = isspace(c);
		if (last_space && !this_space)
			i++;
		last_space = this_space;
	}
	printf("%i\n", i);
	return 0;
}
\end{verbatim}
\figend
\caption{Word counting in C}
\label{fig:c_words}
\end{fig}

There are several reasons that the Haskell version does not perform at the same speed as the C version:

\begin{description}
\item[Intermediate Lists] One of the reasons for the slowdown in the Haskell version is that many intermediate lists are produced and consumed as the program proceeds. The |getContents| function produces a list of characters, |words| consumes this list and produces a list of a list of characters, |length| then consumes the outermost list. The equivalent C program has no allocation.
\item[Higher Order Arguments] The |words| function is defined using the function |span|, which takes a predicate and splits the input list when the predicate becomes true. The predicate is passed as a higher order function, which is constant on all applications.
\item[Laziness] The Haskell program proceeds in a lazy manner, demanding one character from |getContents|, then processing it with each of the functions in the pipeline. At each stage, a lazy thunk for the remainder of the function is created.
\end{description}

By using the optimiser developed in this paper we can eliminate all these overheads, resulting in a program that performs \textit{faster} than the equivalent C version. The central idea of the optimiser is that we attempt to evaluate as much of the program at compile time as possible, leaving a residual program consisting of only actions dependent on the input data.

Our goal is to make high-level Haskell programs perform as fast as low-level Haskell programs, eliminating the need to optimise Haskell programs in the kind of detail currently required for high performance programs. We require no annotations on any part of the program, even library functions, in contrast to other approaches.

\subsection{Roadmap}

Insert here

\section{Core Language}

\begin{fig}
\begin{code}
expr  =  v                                          {-" \text{  variable} "-}
      |  c                                          {-" \text{  constructor} "-}
      |  f                                          {-" \text{  function} "-}
      |  x y                                        {-" \text{  application} "-}
      |  \v -> x                                    {-" \text{  lambda abstraction} "-}
      |  let v = x in y                             {-" \text{  let binding} "-}
      |  case x of {p_1 -> y_1 ; ... ; p_n -> y_n}  {-" \text{  case expression} "-}

pat   =  c vs_
\end{code}

Where |v| ranges over variables, |C| ranges over constructors, |f| ranges over functions, |x|, |y| and |z| range over expressions and |p| ranges over patterns.
\bigskip
\figend
\caption{Core syntax}
\label{fig:core}
\end{fig}

All our optimisations operate on a standard Core language, documented in \cite{me:yhc_core}. The expression data type is given in Figure \ref{fig:core}. A program is a mapping of function names to expressions. Our Core language is higher order and lazy, but lacks much of the syntactic sugar found in Haskell. Pattern matching occurs only in case expressions, and all case expressions are exhaustive. All names are fully qualified. Haskell's type classes have been removed by the dictionary transformation \cite{wadler:type_classes}.

The Yhc compiler, a fork of nhc \cite{nhc}, can output Core files using a single flag. Yhc can also link in all definitions from all required libraries, and can produce a single Core file representing the entire program.

The primary difference between our Core language and that of the GHC compiler \cite{ghc_core} is that ours is untyped. The Core is generated from well-typed Haskell, and is guaranteed not to fail with a type error. All the transformations we implement could be implemented equally well in a typed Core language. We prefer to work in an untyped Core language for simplicity of implementation.

In order to avoid accidental variable name clashes while performing transformations, we demand that all variables within a program are unique. All transformations may assume this invariant, and must ensure it as a postcondition.

\section{Optimisation}

Our optimisation procedure takes a Core program as input, and produces a new Core program, that has the same effect as the original -- hopefully with improved performance. We do not make small changes to the original program, but instead evaluate some of the program at compile time, leaving a residual program to be run.

Each function in the output program is associated with an expression in the input program. The expression in the output program is an optimised version of the expression in the input program. Our optimisation proceeds by starting at the |main| function, and optimising the expression associated with |main|. Once the expression has been optimised, the outermost element in the expression becomes part of the residual program. All the inner expressions are assigned names, which become functions in the residual program. Each of these new functions are then optimised as before.

\begin{fig}
\begin{code}
_O\<case x of alts_  \> =  case _O\<x\> \? of alts_
_O\<let v = x in y   \> =  let v = _O\<x\> \? in _O\<y\>
_O\<x y              \> =  _O\<x\> \? y
_O\<function         \> =  _O\<unfold f\>
                           where f {-" \hbox{ is a non-primitive, non-CAF function} "-}
_O\<x                \> =  x
\end{code}
\figend
\caption{Optimisation function, |_O|}
\label{fig:optimise}
\end{fig}

\begin{fig}
\begin{code}
case (case x of {p_1 -> y_1 ; ... ; p_n -> y_n}) of alts_
    => case x of  {  p_1  -> case y_1 of alts_
                  ;  ...
                  ;  p_n  -> case y_n of alts_ }

case c xs_ of {... ; c vs_ -> y ; ...}
    => y[vs_/xs_]

case v of {... ; c vs_ -> x ; ...}
    => case v of {... ; c vs_ -> x[v/c vs_]; ...}

case (let v = x in y) of alts_
    => let v = x in case y of alts_

(let v = x in y) xs_
    => let v = x in y xs_

(case x of {p_1 -> y_1 ; ... ; p_n -> y_n}) xs_
    => case x of {p_1 -> y_1 xs_ ; ... ; p_n -> y_n xs_}

(\v -> x) y
    => let v = y in x

let v = x in (case y of {p_1 -> y_1 ; ... ; p_n -> y_n})
    => case y of  {  p_1  -> let v = x in y_1
                  ;  ...
                  ;  p_n  -> let v = x in y_n}
    where v {-" \hbox{is not used in} "-} y

let v = x in y
    => y[v/x]
    where x {-" \hbox{is a lambda, variable, or used once in } "-} y

let v = c x_1 ... x_n in y
    =>  let v_1 = x_1 in
        ...
        let v_n = x_n in
        y[v/c x_1 ... x_n]
    where v_1 ... v_n {-" \hbox{ are fresh} "-}
\end{code}
\figend
\caption{Simplification rules}
\label{fig:simplify}
\end{fig}

The optimisation of an expression is performed using the |_O| function in Figure \ref{fig:evaluate}, and the simplification rules in Figure \ref{fig:simplify}. We define |_OO| to be the fixed point of applying both |_O| and the simplification rules. The |_O| function proceeds much like evaluation at run time, but stops if the next expression to reduce is a free variable, a constructor, a primitive, or a CAF (constant applicative form -- see \S\ref{sec:caf} for more details). The one difference is that in a |let| expression the bound variable and the inner expression are \textit{both} optimised -- see \S\ref{sec:let}.

Let us take a simple example:

\begin{code}
main = \xs -> map inc xs

map = \f -> \xs -> case  xs of
                         []    -> []
                         y:ys  -> f y : map f ys

inc = \x -> x+1
\end{code}

This program defines a |main| function which increments each value in the list by one. Note that |f| is passed around at runtime, when it could be frozen in at compile time. By following the optimisation procedure we end up with:

\begin{code}
main = \xs -> case  xs of
                    []    -> []
                    y:ys  -> f0 y ys

f0 = \y -> \ys -> (y+1) : main ys
\end{code}

And finally by performing some trivial inlining we can obtain:

\begin{code}
main = \xs -> case  xs of
                    []    -> []
                    y:ys  -> (y+1) : main ys
\end{code}

The residual program is now optimised -- there is no runtime passing of the |inc| function, only direct a arithmetic operation.

Next we show another example, which has an instance of list deforestation \cite{wadler:deforestation}. Taking the program:

\begin{code}
main xs = map (+1) (map (*2) xs)

map f xs = case  xs of
                 []    -> []
                 y:ys  -> f y : map f ys
\end{code}

This is transformed (after trivial inlining) into:

\begin{code}
main xs = case  xs of
               []    -> []
               y:ys  -> (y*2)+1 : main ys
\end{code}

Here the intermediate list has been removed, and the higher order functions have been specialised.


\subsection{Termination}
\label{sec:termination}

The main problem with the method as presented so far is that it may not terminate. There are several ways to that non-termination can arise -- we consider, and eliminate, each one in turn.

\subsubsection{Infinite Unfolding}

Consider the definition:

\begin{code}
name = \x -> name x
\end{code}

This program would not terminate at runtime, but in a lazy language it is entirely possible that the resultant value would never be demanded, and the program would terminate. Also, while it is unlikely someone would write such a program, it is possible to arise by other transformations.

If the expression |name x| was being optimised then the optimisation function |_OO| would not terminate. We can solve this problem by either bounding the number of unfoldings, or by keeping a list of previous values in the optimisation of an expression. In practice, this situation is rare, and either choice is acceptable. We choose to bound the number of unfoldings to an excessively large number -- resulting in a slight slow down at compilation time of an infinite unfolding, but not impacting either runtime or memory consumption in the common case.

\subsubsection{Accumulating parameters}

Consider the definition:

\begin{code}
reverseAcc = \xs -> \ys -> case  xs of
                                 []    -> []
                                 z:zs  -> reverseAcc zs (z:ys)
\end{code}

This function is the standard |reverse| function, with an accumulator. The problem is that successive iterations of the optimisation produce progressively larger subexpressions. Initially a function will be created for |reverseAcc _ _|, then for |reverseAcc _ (_:_)|, then |reverseAcc _ (_:_:_)|. If left unchecked there would be an infinite number of functions created in the residual program.

The solution is to bound the size of the input expression associated with each function. The size of the expression being optimised can be reduced by lifting some aspect of the expression into a let binding, then placing this let binding in the residual program. By bounding the size of the expression, we bound the number of functions in the residual program.

If the bound is too high, optimisation will take programs will take too long, the residual program will be excessively large and some functions will have too many arguments. If the bound is too low then we will have limited optimisation. We will come back to the issue of the size of this bound in the results sections \ref{sec:haskell_results}.

\subsubsection{Direct Repetition}

While the two changes presented above do guarantee termination, it is often useful to detect an expression which appears to be repeating, and preemptively bound it. Consider the |reverseAccumulator| example -- the recursive pattern is an instance of \textit{direct repetition}. An expression |x| is directly repeating if |x ~= alpha (alpha beta)| where |beta| is an expression, |alpha| is a non-identity function from an expression to an expression and |~=| is equality where all variables are considered equal.

Some examples of expressions which have direct repetition:

\begin{code}
x:y:xs
f (f x)
case x_1 of {[] -> nil ; y:ys -> case x_2 of {[] -> nil ; z:zs -> cons}}
\end{code}

If direct repetition is encountered, then the repeating expression is lifted to a top-level let binding, and output directly into the residual program.

\subsection{Let Bindings}
\label{sec:let}

The rule for let bindings in Figure \ref{fig:optimise} is curious. While all other rules simply follow evaluation order, the let rule optimises \textit{both} the bound expression and the inner expression. This is a critical choice, which enhances the optimisation performed by the system.

In the Core language a let expression introduces a binding, which is shared. Given the expression |let v = x in y|, if |v| is referred to multiple times in |y|, then the expression |x| will only be computed once. It is important when applying |_OO| that shared let bindings are not unshared. Consider the following program:

\begin{code}
let v = expensive
in v + v
\end{code}

If the expression |v| was unshared, then |expensive| would be computed twice, slowing down the runtime. Yet, by inlining certain let expressions, better optimisation can be achieved. Taking the following fragment from a previous example:

\begin{code}
let f = inc
in f y : map f ys
\end{code}

If |f| is not inlined, then the recursive call to |map| would still contain a higher-order parameter. But at the same time, it is not easy to tell whether |inc| is expensive or not. The solution is to first optimise |inc|, leading to:

\begin{code}
let f = \x -> x + 1
in f y : map f ys
\end{code}

After this optimisation, it is now clear that |f| is a lambda, so by inlining it there will be no additional computation.

\subsection{CAF's}
\label{sec:caf}

A CAF (constant applicative form) is a top level function of zero arguments. In Haskell, these CAF values are computed at most once per program run, and retained. Consider the program:

\begin{code}
caf = expensive

main = caf + caf
\end{code}

In this program |caf| would only be computed once. If a CAF function is inlined then this may result in a computation being performed more than would otherwise occur. To ensure that we do not duplicate computations, we never inline CAF's.

\section{Benchmarks Versus C}

The most comprehensive inter-language benchmarking effort is the Programming Language Shootout \cite{shootout}, where a variety of tasks are benchmarked in multiple languages with multiple implementations. Unfortunately, in order to ensure a balanced comparison, many of the restrictions on the benchmarks directly harm lazy languages. Inspired by their approach, we have attempted to define some simpler benchmarks on which it is possible to directly compare Haskell to C.

The set of benchmarks we have chosen are inspired by the Unix \texttt{wc} command -- namely character, word and line counting. In all cases we require to read a file from the standard input, and perform the computation. In order to ensure that we test computation speed, not IO speed (which is usually a product of the underlying buffering system, rather than the compilation prowess) we demand that all input is read using the standard C |getchar| function only. Any buffering improvements, such as chunked reading or memory mapping of files, could be performed equally in all compilers.

All the C versions are transformed into state machines, where characters are read in a loop, and an accumulator is kept -- much the same as in Figure \ref{fig:c_words}. The Haskell versions all follow the same pattern as in the Introduction, merely replacing |words| with |lines|, or removing the |words| function for character counting.

We performed all benchmarks on a Windows XP, 3GHz hyperthreaded, 1Gb RAM machine. The C versions used GCC version n.n with -O3. The pure Haskell version used GHC 6.6.1 with -O2. The Supero version was compiled using our optimiser, then written back as a Haskell file, and compiled once more with GHC 6.6.1 with -O2.

The result of the benchmarks are given here.

\begin{fig}
\begin{barenv}
\setwidth{20}
\setdepth{0}
\sethspace{0.05}
\setstretch{6}
\setnumberpos{empty}
% \setxaxis{0}{1}{1}
% \setxname{$n$}
\setyaxis{0}{25}{5} \setyname{Seconds}
\bar{6}{1}
\bar{6.3}{2}[characters]
\bar{12.5}{3}
\bar{0}{0}
\bar{6.2}{1}
\bar{6.5}{2}[lines]
\bar{17}{3}
\bar{0}{0}
\bar{7.3}{1}
\bar{6.9}{2}[words]
\bar{22}{3}
\end{barenv}
\vspace{0.5cm}
\begin{barenv}
\legend{1}{C}
\legend{2}{Supero}
\legend{3}{GHC}
\end{barenv}
\figend
\caption{Example diagram}
\label{fig:c_results}
\end{fig}

\subsection{Identified Haskell Speedups}

In our exploration of the performance bottlenecks in the Haskell variant we identified two reasons for Hsakell underperforming.

The first is that |isSpace| in Haskell is significantly more expensive than the C |isspace|. The solution we to use an FFI call to the C |isspace| in all cases, removing this source of variance. A GHC bug has been filed about the slow performance of |isspace|, so hopefully this will improve in time.

The second is that the |words| function in Haskell performs two additional |isspace| tests per word read. We have transformed the |words| function to eliminate these unnecessary tests, and have submitted this code for inclusion in a future release of the standard libraries.

\subsection{Potential Haskell Speedups}

There are a number of reasons that the Haskell underperforms relative to the C version.

Lack of strictness information

Heap checks

Stack checks

\subsection{Haskell Outperforms C}

The reason Haskell outperforms C is that the C has redundant flow information. By moving the boolean into the program counter you can go faster. Unfortunately releasing this flow control in C is challenging! Using the |goto| keyword is not appropriate, as typically this turns off many critical optimisations in the C compiler. It can be done, using a nested |while| loop, in a function, and using |return| to break from the inner loop. This solution would not scale to a three-valued control structure, but could be used to achieve higher performance in word counting -- at the cost of code complication and duplication.

\section{Benchmarks Versus Haskell}

The standard benchmark suite in Haskell is the nofib suite, and more recently the nobench suite has added a few benchmarks and removed many. A typical Haskell program is huge, because of factors like dictionaries etc. Because of this, we have limited our focus to a small number of benchmarks drawn from the smallest section of the nobench suite. We have deliberate chosen programs which do not do large amounts of IO, but instead are compute bound programs.

For this task it is important to clarify what optimisations GHC is doing, and which are being performed by Supero. We can broadly divide those optimisations that GHC is doing into those that benefit Supero generated code, and those which do not. Things like strictness analysis and the low-level code optimisations benefit both Supero and GHC. On the other hand, things like |foldr|/|build| fusion, which rely on precisely named functions, are of no benefit to Supero. Since Supero changes all the identifiers, and does not use any GHC provided library functions, any GHC transformation relying on named identifiers will not apply. The other optimisation that GHC benefits from, but which is not applied to Supero code, is dictionary specialisation. In order for Supero to draw with GHC, it would be necessary to perform all of these transformations in the Supero optimiser.

\begin{fig}
\begin{barenv}
\setwidth{20}
\setdepth{0}
\sethspace{0.5}
\setstretch{1}
\setnumberpos{empty}
% \setxaxis{0}{1}{1}
% \setxname{$n$}
\setyaxis{0}{100}{10} \setyname{Relative to GHC}
\bar{0}{0}
\bar{75}{1}[digits-of-e2]
\bar{0}{0}
\bar{90}{1}[digits-of-e1]
\bar{0}{0}
\bar{35}{1}[exp3\_8]
\bar{0}{0}
\bar{87}{1}[primes]
\bar{0}{0}
\bar{78}{1}[queens]
\bar{0}{0}
\end{barenv}
\figend
\caption{Time relative to GHC being 100}
\label{fig:haskell_results}
\end{fig}


\section{Related Work}

Partial evaluation - not really that related.

Supercompilation - quite related.

Deforestation - quite related.

Other transformations - we generalise SpecConstr, inlining etc.

\section{Conclusion}

\paragraph{Acknowledgements} Thanks to Simon Peyton Jones, Simon Marlow and Tim Chevalier for help understanding the low-level details of GHC.

\bibliographystyle{plain}

\bibliography{supero}

\end{document}
